{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvckuBkWTHDm"
      },
      "source": [
        "# Lab 09 XOR - Logistic Regression - Eager Excuetion\n",
        "* XOR 문제를 Logistic Regression을 활용해 풀어보도록 하겠습니다.\n",
        "\n",
        "### 기본 Library 선언 및 Tensorflow 버전 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkPWuImFTHDo",
        "outputId": "3e4ed05f-4a31-4e8b-c51f-b31b956d34b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "\n",
        "# tf.enable_eager_execution()\n",
        "tf.random.set_seed(777)  # for reproducibility\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYw66z84THDo"
      },
      "source": [
        "### 강의에 설명할 Data입니다\n",
        "* x_data가 2차원 배열이기에 2차원 공간에 표현하여 x1과 x2를 기준으로 y_data 0과 1로 구분하는 예제입니다\n",
        "* 붉은색과 푸른색으로 0과 1을 표시해 보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "rI-WObyyTHDp",
        "outputId": "f4245a3d-026e-4808-8f90-dac0bbfbb1c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x_data = [[0, 0],\n",
        "          [0, 1],\n",
        "          [1, 0],\n",
        "          [1, 1]]\n",
        "y_data = [[0],\n",
        "          [1],\n",
        "          [1],\n",
        "          [0]]\n",
        "\n",
        "plt.scatter(x_data[0][0],x_data[0][1], c='red' , marker='^')\n",
        "plt.scatter(x_data[3][0],x_data[3][1], c='red' , marker='^')\n",
        "plt.scatter(x_data[1][0],x_data[1][1], c='blue' , marker='^')\n",
        "plt.scatter(x_data[2][0],x_data[2][1], c='blue' , marker='^')\n",
        "\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dv2tocFTHDp"
      },
      "source": [
        "##  Tensorflow Eager\n",
        "### 위 Data를 기준으로 XOR처리를 위한 모델을 만들도록 하겠습니다\n",
        "* Tensorflow data API를 통해 학습시킬 값들을 담는다 (Batch Size는 한번에 학습시킬 Size로 정한다)\n",
        "* preprocess function으로 features,labels는 실재 학습에 쓰일 Data 연산을 위해 Type를 맞춰준다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6M1ZhxpcTHDp"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data)).batch(len(x_data))\n",
        "\n",
        "def preprocess_data(features, labels):\n",
        "    features = tf.cast(features, tf.float32)\n",
        "    labels = tf.cast(labels, tf.float32)\n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1bAG-ZzTHDp"
      },
      "source": [
        "## 1) Logistic Regression으로 XOR모델을 만들어 보겠습니다\n",
        "### W와 b은 학습을 통해 생성되는 모델에 쓰이는 Wegith와 Bias (초기값을 variable : 0이나 Random값으로 가능 tf.random_normal([2, 1]) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHz6EhHQTHDp",
        "outputId": "285f5143-c1e6-4bbb-ecb6-cad2e07fb25e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W = [[0.]\n",
            " [0.]], B = [0.]\n"
          ]
        }
      ],
      "source": [
        "W = tf.Variable(tf.zeros([2,1]), name='weight')\n",
        "b = tf.Variable(tf.zeros([1]), name='bias')\n",
        "print(\"W = {}, B = {}\".format(W.numpy(), b.numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGCzdrzVTHDq"
      },
      "source": [
        "### Sigmoid 함수를 가설로 선언합니다\n",
        "* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.sigmoid(tf.matmul(X, W) + b)와 같습니다\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_1P2NSsoTHDq"
      },
      "outputs": [],
      "source": [
        "def logistic_regression(features):\n",
        "  hypothesis  = tf.math.divide(1., 1. + tf.math.exp(tf.matmul(features, W) + b))\n",
        "  # hypothesis  =  tf.sigmoid(tf.matmul(features, W) + b)\n",
        "  return hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8tjHR5gTHDq"
      },
      "source": [
        "### 가설을 검증할 Cost 함수를 정의합니다\n",
        "$$\n",
        "\\begin{align}\n",
        "cost(h(x),y) & = −log(h(x))  &  if  &  y=1 \\\\\\\\\\\n",
        "cost(h(x),y) & = -log(1−h(x))  &  if  &  y=0\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqVUCAqNTHDq"
      },
      "source": [
        "* 위 두수식을 합치면 아래과 같습니다\n",
        "$$\n",
        "\\begin{align}\n",
        "cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "b2zTZP02THDq"
      },
      "outputs": [],
      "source": [
        "def loss_fn(hypothesis, features, labels):\n",
        "    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features)) + (1 - labels) * tf.math.log(1 - hypothesis))\n",
        "    return cost\n",
        "\n",
        "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_FLkzt1THDq"
      },
      "source": [
        "### 추론한 값은 0.5를 기준(Sigmoid 그래프 참조)로 0과 1의 값을 리턴합니다.\n",
        "* Sigmoid 함수를 통해 예측값이 0.5보다 크면 1을 반환하고 0.5보다 작으면 0으로 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ZTUfYvGZTHDq"
      },
      "outputs": [],
      "source": [
        "def accuracy_fn(hypothesis, labels):\n",
        "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BixacmsyTHDq"
      },
      "source": [
        "### GradientTape를 통해 경사값을 계산합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "cyYXtFdpTHDr"
      },
      "outputs": [],
      "source": [
        "def grad(hypothesis, features, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss_fn(logistic_regression(features),features,labels)\n",
        "    return tape.gradient(loss_value, [W,b])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1PboiiKTHDr"
      },
      "source": [
        "### Tensorflow를 통한 실행을 위해 Session를 선언합니다.\n",
        "* 위의 Data를 Cost함수를 통해 학습시킨 후 모델을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uschbVRITHDr",
        "outputId": "c5fd6ec1-8790-40ef-bf19-3e56ed869404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, Loss: 0.6931\n",
            "Iter: 100, Loss: 0.6931\n",
            "Iter: 200, Loss: 0.6931\n",
            "Iter: 300, Loss: 0.6931\n",
            "Iter: 400, Loss: 0.6931\n",
            "Iter: 500, Loss: 0.6931\n",
            "Iter: 600, Loss: 0.6931\n",
            "Iter: 700, Loss: 0.6931\n",
            "Iter: 800, Loss: 0.6931\n",
            "Iter: 900, Loss: 0.6931\n",
            "Iter: 1000, Loss: 0.6931\n",
            "W = [[0.]\n",
            " [0.]], B = [0.]\n",
            "Testset Accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 1001\n",
        "\n",
        "for step in range(EPOCHS):\n",
        "    for features, labels  in dataset:\n",
        "        features, labels = preprocess_data(features, labels)\n",
        "        grads = grad(logistic_regression(features), features, labels)\n",
        "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
        "        if step % 100 == 0:\n",
        "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))\n",
        "print(\"W = {}, B = {}\".format(W.numpy(), b.numpy()))\n",
        "x_data, y_data = preprocess_data(x_data, y_data)\n",
        "test_acc = accuracy_fn(logistic_regression(x_data),y_data)\n",
        "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Rabz14LcTHDr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}