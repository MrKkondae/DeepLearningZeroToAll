{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1xk-jH6yFS7"
      },
      "source": [
        "# Lab 09 XOR - tensorboard - eager\n",
        "* XOR 문제를 Deep Neural Network 활용해 풀어보고 Tensorboard에 출력해 보도록 하겠습니다.\n",
        "\n",
        "### 기본 Library 선언 및 Tensorflow 버전 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "scrolled": true,
        "id": "HHUTeWB4yFS8",
        "outputId": "56766115-468d-4b57-a4c5-0f0fb5333cac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "#import tensorflow.contrib.eager as tfe\n",
        "\n",
        "#tf.enable_eager_execution()\n",
        "tf.random.set_seed(777)  # for reproducibility\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-EXlHUsyFS9"
      },
      "source": [
        "### 강의에 설명할 Data입니다\n",
        "* x_data가 2차원 배열이기에 2차원 공간에 표현하여 x1과 x2를 기준으로 y_data 0과 1로 구분하는 예제입니다\n",
        "* 붉은색과 푸른색으로 0과 1을 표시해 보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "scrolled": true,
        "id": "uautaaWtyFS9",
        "outputId": "83714a8c-8ba1-496d-ef15-29add1f60880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x_data = [[0, 0],\n",
        "          [0, 1],\n",
        "          [1, 0],\n",
        "          [1, 1]]\n",
        "y_data = [[0],\n",
        "          [1],\n",
        "          [1],\n",
        "          [0]]\n",
        "\n",
        "plt.scatter(x_data[0][0],x_data[0][1], c='red' , marker='^')\n",
        "plt.scatter(x_data[3][0],x_data[3][1], c='red' , marker='^')\n",
        "plt.scatter(x_data[1][0],x_data[1][1], c='blue' , marker='^')\n",
        "plt.scatter(x_data[2][0],x_data[2][1], c='blue' , marker='^')\n",
        "\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWoAfq-1yFS9"
      },
      "source": [
        "##  Tensorboard\n",
        "### 위 Data를 기준으로 XOR처리를 위한 모델을 만들도록 하겠습니다\n",
        "* 위의 Data를 4Layer의 Neural Network를 통해 학습시킨 후 모델을 생성합니다.\n",
        "* tensorboard --logdir=./logs/ 실행합니다.\n",
        "* summary 값을 logs폴더에 저장하고 아래 명령어로 실행해서 확인한다 (http://0.0.0.0:6006)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "d57awjUtyFS9"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data)).batch(len(x_data))\n",
        "\n",
        "def preprocess_data(features, labels):\n",
        "    features = tf.cast(features, tf.float32)\n",
        "    labels = tf.cast(labels, tf.float32)\n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4Z647r7yFS-"
      },
      "source": [
        "### Deep Neural Network를 통해 XOR해결\n",
        "* 위의 Data를 4Layer의 Neural Network를 통해 학습시킨 후 모델을 생성합니다.\n",
        "* 각각의 값을 histogram으로 tensorboard에 저장한다 (Model)\n",
        "* 각각의 값을 scalar값으로 tensorboard에 저장한다 (cost, accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "FhknGCsIyFS-"
      },
      "outputs": [],
      "source": [
        "W1 = tf.Variable(tf.random.normal([2, 10]), name='weight1')\n",
        "b1 = tf.Variable(tf.random.normal([10]), name='bias1')\n",
        "\n",
        "W2 = tf.Variable(tf.random.normal([10, 10]), name='weight2')\n",
        "b2 = tf.Variable(tf.random.normal([10]), name='bias2')\n",
        "\n",
        "W3 = tf.Variable(tf.random.normal([10, 10]), name='weight3')\n",
        "b3 = tf.Variable(tf.random.normal([10]), name='bias3')\n",
        "\n",
        "W4 = tf.Variable(tf.random.normal([10, 1]), name='weight4')\n",
        "b4 = tf.Variable(tf.random.normal([1]), name='bias4')\n",
        "\n",
        "def neural_net(features):\n",
        "    layer1 = tf.sigmoid(tf.matmul(features, W1) + b1)\n",
        "    layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
        "    layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
        "    hypothesis = tf.sigmoid(tf.matmul(layer3, W4) + b4)\n",
        "\n",
        "    with writer.as_default():\n",
        "        tf.summary.histogram(\"weights1\", W1, step=global_step)\n",
        "        tf.summary.histogram(\"biases1\", b1, step=global_step)\n",
        "        tf.summary.histogram(\"layer1\", layer1, step=global_step)\n",
        "\n",
        "        tf.summary.histogram(\"weights2\", W2, step=global_step)\n",
        "        tf.summary.histogram(\"biases2\", b2, step=global_step)\n",
        "        tf.summary.histogram(\"layer2\", layer2, step=global_step)\n",
        "\n",
        "        tf.summary.histogram(\"weights3\", W3, step=global_step)\n",
        "        tf.summary.histogram(\"biases3\", b3, step=global_step)\n",
        "        tf.summary.histogram(\"layer3\", layer3, step=global_step)\n",
        "\n",
        "        tf.summary.histogram(\"weights4\", W4, step=global_step)\n",
        "        tf.summary.histogram(\"biases4\", b4, step=global_step)\n",
        "        tf.summary.histogram(\"hypothesis\", hypothesis, step=global_step)\n",
        "    return hypothesis\n",
        "\n",
        "def loss_fn(hypothesis, labels):\n",
        "    cost = -tf.reduce_mean(labels * tf.math.log(hypothesis) + (1 - labels) * tf.math.log(1 - hypothesis))\n",
        "    with writer.as_default() :\n",
        "        tf.summary.scalar('loss', cost, step=global_step)\n",
        "    return cost\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "\n",
        "def accuracy_fn(hypothesis, labels):\n",
        "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n",
        "    return accuracy\n",
        "\n",
        "def grad(hypothesis, features, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss_fn(neural_net(features),labels)\n",
        "    return tape.gradient(loss_value, [W1, W2, W3, W4, b1, b2, b3, b4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UzQ0wMHyFS-"
      },
      "source": [
        "* summary 값을 logs폴더에 저장하고 아래 명령어로 실행해서 확인한다 (http://0.0.0.0:6006)\n",
        "* tensorboard --logdir=./logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ZdSzxSEHyFS-",
        "outputId": "2c081fc9-ae08-48ce-8285-7d3c033c7c42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, Loss: 0.9517\n",
            "Iter: 50, Loss: 0.6936\n",
            "Iter: 100, Loss: 0.6923\n",
            "Iter: 150, Loss: 0.6912\n",
            "Iter: 200, Loss: 0.6901\n",
            "Iter: 250, Loss: 0.6890\n",
            "Iter: 300, Loss: 0.6879\n",
            "Iter: 350, Loss: 0.6867\n",
            "Iter: 400, Loss: 0.6855\n",
            "Iter: 450, Loss: 0.6842\n",
            "Iter: 500, Loss: 0.6827\n",
            "Iter: 550, Loss: 0.6811\n",
            "Iter: 600, Loss: 0.6793\n",
            "Iter: 650, Loss: 0.6772\n",
            "Iter: 700, Loss: 0.6749\n",
            "Iter: 750, Loss: 0.6722\n",
            "Iter: 800, Loss: 0.6690\n",
            "Iter: 850, Loss: 0.6654\n",
            "Iter: 900, Loss: 0.6611\n",
            "Iter: 950, Loss: 0.6561\n",
            "Iter: 1000, Loss: 0.6502\n",
            "Iter: 1050, Loss: 0.6432\n",
            "Iter: 1100, Loss: 0.6349\n",
            "Iter: 1150, Loss: 0.6251\n",
            "Iter: 1200, Loss: 0.6134\n",
            "Iter: 1250, Loss: 0.5992\n",
            "Iter: 1300, Loss: 0.5821\n",
            "Iter: 1350, Loss: 0.5612\n",
            "Iter: 1400, Loss: 0.5357\n",
            "Iter: 1450, Loss: 0.5047\n",
            "Iter: 1500, Loss: 0.4677\n",
            "Iter: 1550, Loss: 0.4248\n",
            "Iter: 1600, Loss: 0.3774\n",
            "Iter: 1650, Loss: 0.3281\n",
            "Iter: 1700, Loss: 0.2798\n",
            "Iter: 1750, Loss: 0.2356\n",
            "Iter: 1800, Loss: 0.1971\n",
            "Iter: 1850, Loss: 0.1649\n",
            "Iter: 1900, Loss: 0.1385\n",
            "Iter: 1950, Loss: 0.1173\n",
            "Iter: 2000, Loss: 0.1003\n",
            "Iter: 2050, Loss: 0.0865\n",
            "Iter: 2100, Loss: 0.0754\n",
            "Iter: 2150, Loss: 0.0663\n",
            "Iter: 2200, Loss: 0.0588\n",
            "Iter: 2250, Loss: 0.0526\n",
            "Iter: 2300, Loss: 0.0474\n",
            "Iter: 2350, Loss: 0.0429\n",
            "Iter: 2400, Loss: 0.0392\n",
            "Iter: 2450, Loss: 0.0359\n",
            "Iter: 2500, Loss: 0.0331\n",
            "Iter: 2550, Loss: 0.0306\n",
            "Iter: 2600, Loss: 0.0285\n",
            "Iter: 2650, Loss: 0.0265\n",
            "Iter: 2700, Loss: 0.0248\n",
            "Iter: 2750, Loss: 0.0233\n",
            "Iter: 2800, Loss: 0.0220\n",
            "Iter: 2850, Loss: 0.0207\n",
            "Iter: 2900, Loss: 0.0196\n",
            "Iter: 2950, Loss: 0.0186\n",
            "Testset Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 3000\n",
        "log_path = \"./logs/xor_eager_logs_r0_01\"\n",
        "writer = tf.summary.create_file_writer(log_path)\n",
        "# global_step = tf.train.get_or_create_global_step()  # global step variable\n",
        "global_step = tf.Variable(0, trainable=False, dtype=tf.int64, name='global_step')\n",
        "writer.set_as_default()\n",
        "\n",
        "for step in range(EPOCHS):\n",
        "    global_step.assign_add(1)\n",
        "    for features, labels  in dataset :\n",
        "        features, labels = preprocess_data(features, labels)\n",
        "        grads = grad(neural_net(features), features, labels)\n",
        "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W1, W2, W3, W4, b1, b2, b3, b4]))\n",
        "        if step % 50 == 0:\n",
        "            loss_value = loss_fn(neural_net(features),labels)\n",
        "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_value))\n",
        "x_data, y_data = preprocess_data(x_data, y_data)\n",
        "test_acc = accuracy_fn(neural_net(x_data),y_data)\n",
        "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "IXEqHGsYyFS-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "p6Tzv_n1yFS-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}